{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data streaming\n",
    "\n",
    "## Task 4. Botnet profiling task\n",
    "\n",
    "Group 97\n",
    "\n",
    "Choose a probabilistic sequential model (Markov chain, n-grams, state machines, HMMs, ...) Use a sliding window to obtain sequence data. Learn a probabilistic sequential model from the data of one infected host and match its profile with all other hosts from the same scenario. Evaluate how many new infections your method finds and false positives it raises. Can you determine what behaviour your profile detects?\n",
    "\n",
    "Per documentation, the distribution of labels in the NetFlows for scenario 10 in the dataset is:\n",
    "\n",
    "Total flows | Botnet flows    | Normal flows  | C&C flows  | Background flows\n",
    "------------|-----------------|---------------|------------|-------------------\n",
    "1,309,791   | 106,315 (8.11%) | 15,847 (1.2%) | 37 (.002%) | 1,187,592 (90.67%)\n",
    "\n",
    "Reference: \"An empirical comparison of botnet detection methods\" Sebastian Garcia, Martin Grill, Jan Stiborek and Alejandro Zunino. Computers and Security Journal, Elsevier. 2014. Vol 45, pp 100-123. http://dx.doi.org/10.1016/j.cose.2014.05.011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, scale\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from string import ascii_lowercase\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning) # disable specific warning\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filepath for scenario 10 dataset\n",
    "filepath = './data/capture20110818.pcap.netflow.labeled'\n",
    "\n",
    "# read data from the file\n",
    "f = open(filepath, 'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "data = lines[1:] # drop the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_remove_Background(data):\n",
    "    '''data preprocessing\n",
    "    Input\n",
    "    -----\n",
    "    data: string of a data flow\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    o = None, if Background flow (to be removed)\n",
    "    o = cleaned, formated data, if not Background flow\n",
    "    '''\n",
    "    if not 'Background' in data:\n",
    "        s = data.split('\\t')\n",
    "        s = [x for x in s if x] # remove empty elements\n",
    "        if len(s) < 12: # special fix for an outlier string @2011-08-18 12:18:31.264\n",
    "            s = s[0].rsplit(' ', 11) \n",
    "        o = np.array([pd.to_datetime(s[0], format='%Y-%m-%d %H:%M:%S.%f'), # timestamp\n",
    "                      float(s[1]), # duration\n",
    "                      s[2], # protocol\n",
    "                      s[3].split(':')[0], # ScrAddr\n",
    "                      s[5].split(':')[0], # DstAddr\n",
    "                      s[6].lstrip('_').rstrip('_').rstrip(), # flags\n",
    "                      int(s[7]), # Tos\n",
    "                      int(s[8]), # packets\n",
    "                      int(s[9]), # bytes\n",
    "                      int(s[10]), # flows\n",
    "                      s[11].rstrip('\\n').rstrip() # label\n",
    "                     ])\n",
    "    else: # if Background flow\n",
    "        o = None\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list(map(preprocessing_remove_Background, data)) # data preprocessing\n",
    "df = [x for x in df if isinstance(x, np.ndarray)] # remove background flows\n",
    "df = pd.DataFrame(df, columns=['Time', 'Duration', 'Protocol', 'ScrAddr', 'DstAddr', \n",
    "                               'Flags', 'Tos', 'Packets', 'Bytes', 'Flows', 'Label'])\n",
    "df.set_index('Time', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>ScrAddr</th>\n",
       "      <th>DstAddr</th>\n",
       "      <th>Flags</th>\n",
       "      <th>Tos</th>\n",
       "      <th>Packets</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>Flows</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-08-18 10:19:13.347</th>\n",
       "      <td>4.985</td>\n",
       "      <td>TCP</td>\n",
       "      <td>147.32.80.13</td>\n",
       "      <td>147.32.85.88</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>86277</td>\n",
       "      <td>1</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-18 10:19:13.392</th>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>147.32.86.110</td>\n",
       "      <td>74.125.232.214</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-18 10:19:13.411</th>\n",
       "      <td>4.921</td>\n",
       "      <td>TCP</td>\n",
       "      <td>147.32.85.88</td>\n",
       "      <td>147.32.80.13</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3234</td>\n",
       "      <td>1</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-18 10:19:13.460</th>\n",
       "      <td>4.742</td>\n",
       "      <td>TCP</td>\n",
       "      <td>147.32.84.59</td>\n",
       "      <td>74.125.108.208</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>7080</td>\n",
       "      <td>1</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-18 10:19:13.486</th>\n",
       "      <td>0.000</td>\n",
       "      <td>TCP</td>\n",
       "      <td>147.32.84.59</td>\n",
       "      <td>74.125.232.215</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>LEGITIMATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Duration Protocol        ScrAddr         DstAddr  \\\n",
       "Time                                                                        \n",
       "2011-08-18 10:19:13.347     4.985      TCP   147.32.80.13    147.32.85.88   \n",
       "2011-08-18 10:19:13.392     0.000      TCP  147.32.86.110  74.125.232.214   \n",
       "2011-08-18 10:19:13.411     4.921      TCP   147.32.85.88    147.32.80.13   \n",
       "2011-08-18 10:19:13.460     4.742      TCP   147.32.84.59  74.125.108.208   \n",
       "2011-08-18 10:19:13.486     0.000      TCP   147.32.84.59  74.125.232.215   \n",
       "\n",
       "                        Flags  Tos  Packets  Bytes  Flows       Label  \n",
       "Time                                                                   \n",
       "2011-08-18 10:19:13.347    PA    0       91  86277      1  LEGITIMATE  \n",
       "2011-08-18 10:19:13.392     A    0        1     66      1  LEGITIMATE  \n",
       "2011-08-18 10:19:13.411     A    0       49   3234      1  LEGITIMATE  \n",
       "2011-08-18 10:19:13.460     A    0      118   7080      1  LEGITIMATE  \n",
       "2011-08-18 10:19:13.486     A    0        1     60      1  LEGITIMATE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, **normal host 147.32.87.11 is removed** from the analysis because it contains only 4 data flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of infected hosts and normal hosts\n",
    "infected_hosts = ['147.32.84.165', '147.32.84.191', '147.32.84.192', \n",
    "                  '147.32.84.193', '147.32.84.204', '147.32.84.205', \n",
    "                  '147.32.84.206', '147.32.84.207', '147.32.84.208', '147.32.84.209']\n",
    "normal_hosts = ['147.32.84.170', '147.32.84.134', '147.32.84.164',\n",
    "                '147.32.87.36', '147.32.80.9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model training, the chosen infected host is 147.32.84.165.\n",
      "\n",
      "For model testing, IP addresses include: \n",
      "['147.32.84.209', '147.32.87.36', '147.32.84.208', '147.32.84.207', '147.32.80.9', '147.32.84.164', '147.32.84.206', '147.32.84.193', '147.32.84.170', '147.32.84.204', '147.32.84.205', '147.32.84.191', '147.32.84.192', '147.32.84.134']\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# assign one infected host for training\n",
    "INFECTED_HOST = infected_hosts[0]\n",
    "\n",
    "print('For model training, the chosen infected host is {}.\\n'.format(INFECTED_HOST))\n",
    "\n",
    "# the rest are for testing\n",
    "test_hosts = infected_hosts[1:] + normal_hosts\n",
    "shuffle(test_hosts)\n",
    "print('For model testing, IP addresses include: \\n{}'.format(test_hosts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams_profile(host_ip, n_grams=3):\n",
    "    '''\n",
    "    Parameters \n",
    "    ----------\n",
    "    host_ip : ip address of the speficied host\n",
    "    n_grams : number of grams or window length\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    ngrams_profile : profile of the specified host\n",
    "    \n",
    "    '''\n",
    "    # subset data flows associated with the speficied host\n",
    "    df_host = df.loc[(df.ScrAddr == host_ip)|(df.DstAddr == host_ip), \n",
    "                     ['Protocol', 'Packets']] # subset selected features\n",
    "    df_host.Protocol = LabelEncoder().fit_transform(df_host['Protocol']) # label encoding\n",
    "    \n",
    "    # discretise the data flows by clustering\n",
    "    km = MiniBatchKMeans(n_clusters=5, batch_size=300, random_state=42)\n",
    "    scale_df = scale(df_host.values)\n",
    "    discretisation = km.fit_predict(scale_df) # using scaled data\n",
    "\n",
    "    # translate numeric discretisation to strings\n",
    "    num_to_string = {} # create a dict with key = numeric element, value = translated string\n",
    "    for i, element in enumerate(np.unique(discretisation)):\n",
    "        num_to_string[element] = ascii_lowercase[i]\n",
    "    translation = [num_to_string[element] for element in discretisation]\n",
    "\n",
    "    # create ngrams\n",
    "    dict_ngrams = {}\n",
    "    for i in range(0, len(translation)-n_grams-1): # loop through the trasnlated string\n",
    "        token = ''.join(translation[i:(i+n_grams)]) # get token through merging n-gram elements (i to(i+n_grams))\n",
    "        next_element = translation[i+n_grams+1] # get the next element (i+n_grams+1)\n",
    "\n",
    "        if token not in dict_ngrams.keys(): # if new n-grams in key, add key into dict\n",
    "            dict_ngrams[token] = [''.join(next_element)]\n",
    "        else: # if existing n-grams in key, append the next element\n",
    "            dict_ngrams[token].append(next_element)\n",
    "\n",
    "    # calculate likelihoods\n",
    "    ngrams_profile = {} # create a dict with key = ngrams token, \n",
    "                        # values = dict of next elements and their likelihoods\n",
    "    for key in dict_ngrams.keys():\n",
    "        # perform unique counts to the next elements\n",
    "        next_elements, counts = np.unique(dict_ngrams[key], return_counts=True)\n",
    "\n",
    "        likelihood = {}\n",
    "        for i, next_element in enumerate(next_elements): # per next element\n",
    "            likelihood[next_element] = counts[i] / counts.sum() # calculate its likelihood\n",
    "\n",
    "        ngrams_profile[key] = likelihood # append the likelihoods for the token\n",
    "        \n",
    "    return ngrams_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aaa': {'a': 0.9816031537450722, 'b': 0.003942181340341655, 'c': 0.010512483574244415, 'd': 0.001314060446780552, 'e': 0.002628120893561104} ... (showing only the first key, cropped the following)\n"
     ]
    }
   ],
   "source": [
    "# get profile for the specified infect host\n",
    "NGRAMS = 3\n",
    "profile_infected = get_ngrams_profile(INFECTED_HOST, NGRAMS)\n",
    "\n",
    "# print the results\n",
    "print('\\'{}\\': {} ... (showing only the first key, cropped the following)'.format(list(profile_infected.keys())[0],\n",
    "                                                                                  profile_infected[list(profile_infected.keys())[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test model\n",
    "\n",
    "Get the profile for each testing host. Calcualte the distance of the profile with those of the infected host and normal host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_HOST = '147.32.84.207'\n",
    "\n",
    "profile_test = get_ngrams_profile(TEST_HOST, NGRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
